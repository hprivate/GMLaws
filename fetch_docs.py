import os
os.environ.pop("SSLKEYLOGFILE", None)

import requests
import ssl
import time
import json
import csv
from colorama import init, Fore, Style
from datetime import datetime




# åˆå§‹åŒ– colorama
init(autoreset=True)

# å…³é—­ SSL éªŒè¯è­¦å‘Š
requests.packages.urllib3.disable_warnings()
ssl._create_default_https_context = ssl._create_unverified_context

# è‡ªåŠ¨åˆ›å»ºç›®å½•
output_dir = './gmbz_docs'
os.makedirs(output_dir, exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
csv_file_path = os.path.join(output_dir, f'gmbz_docs_{timestamp}.csv')

def print_section(title):
    print(Fore.CYAN + "\nâ”€" * 60)
    print(Fore.CYAN + f"ğŸ“˜ {title}")
    print(Fore.CYAN + "â”€" * 60)

def sanitize_filename(name: str):
    """å»é™¤éæ³•æ–‡ä»¶åå­—ç¬¦"""
    return ''.join(c for c in name if c not in r'\/:*?"<>|').strip()

def fetch_files(download_pdf: bool = True):
    url = "http://www.gmbz.org.cn/main/normsearch.json"

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Accept-Language": "zh-CN,zh;q=0.8",
        "Accept-Encoding": "gzip, deflate",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "X-Requested-With": "XMLHttpRequest",
        "Origin": "http://www.gmbz.org.cn",
        "Connection": "close"
    }

    data = {
        "draw": "1",
        "start": "0",
        "length": "500",
        "search[value]": "",
        "search[regex]": "false"
    }

    for i, name in enumerate([
        "NORM_ISO_ID", "NORM_NAME_C", "NORM_ZT_NAME", "NORM_FLAG_NAME",
        "NORM_NAME_E", "NORM_CO_NAME", "NORM_CA_NAME", "NORM_PUB_DATE",
        "NORM_IMP_DATE", "UP_GB_FLAG", "10"
    ]):
        data[f"columns[{i}][data]"] = name
        data[f"columns[{i}][name]"] = name
        data[f"columns[{i}][searchable]"] = "true"
        data[f"columns[{i}][orderable]"] = "true"
        data[f"columns[{i}][search][value]"] = ""
        data[f"columns[{i}][search][regex]"] = "false"

    data["order[0][column]"] = "0"
    data["order[0][dir]"] = "asc"

    print_section("å¼€å§‹è¯·æ±‚æ ‡å‡†åˆ—è¡¨...")

    try:
        response = requests.post(url, headers=headers, data=data, verify=False, timeout=10)
        response.encoding = 'utf-8'
    except requests.RequestException as e:
        print(Fore.RED + f"âŒ è¯·æ±‚å¤±è´¥ï¼š{e}")
        return

    if response.status_code != 200:
        print(Fore.RED + f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        return

    try:
        content_json = response.json()
    except json.JSONDecodeError as e:
        print(Fore.RED + "âŒ JSONè§£æå¤±è´¥ï¼Œå“åº”å†…å®¹å¦‚ä¸‹ï¼š")
        print(response.text[:500])
        return

    records = content_json.get('data', [])
    print(Fore.GREEN + f"âœ… è·å–åˆ° {len(records)} æ¡è®°å½•ï¼Œæ­£åœ¨å†™å…¥ Excel" + (" å¹¶ä¸‹è½½ PDF..." if download_pdf else "..."))

    with open(csv_file_path, "w", newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["åºå·", "è¡Œæ ‡å·", "æ ‡å‡†ä¸­æ–‡åç§°", "ç±»åˆ«", "çŠ¶æ€", "å‘å¸ƒæ—¥æœŸ", "å®æ–½æ—¥æœŸ", "æ–‡æ¡£ä¸‹è½½é“¾æ¥"])

        for index, line in enumerate(records, start=1):
            norm_id = line.get('NORM_ID', '')
            name_c = line.get('NORM_NAME_C', '')
            zt = line.get('NORM_ZT_NAME', '--')
            flag = line.get('NORM_FLAG_NAME', '--')
            pub_date = line.get('NORM_PUB_DATE', '')
            imp_date = line.get('NORM_IMP_DATE', '')
            file_path = line.get('NORM_APP_ADDR', '')

            download_url = f"http://www.gmbz.org.cn/file/{file_path}" if file_path else ''
            writer.writerow([index, norm_id, name_c, zt, flag, pub_date, imp_date, download_url])

            if download_pdf and file_path:
                safe_name = sanitize_filename(f"{norm_id} {name_c}.pdf")
                file_save_path = os.path.join(output_dir, safe_name)

                if not os.path.exists(file_save_path):
                    try:
                        r = requests.get(download_url, stream=True, verify=False, timeout=15)
                        with open(file_save_path, 'wb') as f:
                            for chunk in r.iter_content(chunk_size=1024):
                                if chunk:
                                    f.write(chunk)
                        print(Fore.GREEN + f"  [+] ä¸‹è½½æˆåŠŸï¼š{safe_name}")
                    except Exception as e:
                        print(Fore.RED + f"  [!] ä¸‹è½½å¤±è´¥ï¼š{safe_name}ï¼ŒåŸå› ï¼š{e}")
                else:
                    print(Fore.YELLOW + f"  [=] å·²å­˜åœ¨è·³è¿‡ï¼š{safe_name}")

    print_section("å…¨éƒ¨å®Œæˆ")
    print(Fore.GREEN + f"âœ… åˆ—è¡¨æ–‡ä»¶å’Œæ–‡æ¡£ä¿å­˜åœ¨ï¼š{output_dir}\n")

if __name__ == '__main__':
    print_section("æ ‡å‡†çˆ¬å–å·¥å…·")
    user_input = input(Fore.MAGENTA + "æ˜¯å¦åªç”Ÿæˆ Excel åˆ—è¡¨è€Œä¸ä¸‹è½½ PDFï¼Ÿ(y/n): ").strip().lower()
    only_csv = user_input == 'y'
    fetch_files(download_pdf=not only_csv)
